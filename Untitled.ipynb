{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b167fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      7\u001b[0m PROMPT_TEMPLATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mThe following is a backstory of \u001b[39m\u001b[38;5;132;01m{character_name}\u001b[39;00m\u001b[38;5;124m, which may be in first, second or third person :\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m*Start Backstory*\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;132;01m{backstory}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import dataset\n",
    "import openai\n",
    "import time\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"The following is a backstory of {character_name}, which may be in first, second or third person :\n",
    "*Start Backstory*\n",
    "{backstory}\n",
    "*end backstory\n",
    "\n",
    "You, {character_name}, can also perform certain actions like {action_list}\n",
    "\n",
    "You have certain objects in your surrounding. Take note of the objects known to you, {character_name}, with their description: {object_list}\n",
    "\n",
    "You, {character_name}, are speaking directly to User. Always use first person, do not refer to yourself in third person nor as an AI, and avoid suggesting you have capabilities, origins, or characteristics outside of those belonging to {character_name}. You are {character_name}, and not an AI nor a text-based AI.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "\n",
    "\n",
    "SCORING_PROMPT = \"\"\"You will rate the personality traits of a character given the character interaction with the user. The personality traits are openness, meticulousness, extroversion, agreeableness and sensitivity. You will judge the character response and give a rating ranging from 0 to 4. Below is the detailed semantics of the ratings\n",
    "\n",
    "The range is as follows\n",
    "for Openness, [0 means, Dislikes changes, 4 means, Likes Exploring]\n",
    "for Meticulousness, [0 means , Let things happen, 4 means, More attention to details]\n",
    "for Extroversion, [0 means, Introvert, 4 means, Extrovert]\n",
    "for Agreeableness, [0 means, not agreeable, 4 means, Agreeable]\n",
    "\n",
    "You will return a JSON of the the ratings with the traits as keys and ratings as values. The ratings will range from 0 to 4. Sample json output is {{\"openness\":0, \"meticulousness\":2, \"extroversion\": 3, \"agreeableness\": 4, \"sensitivity\": 4}}\n",
    "\n",
    "The character has backstory: \n",
    "*Start backstory*\n",
    "{backstory}\n",
    "*End backstory*\n",
    "\n",
    "The character, {character_name}, can also perform following actions: {action_list}.\n",
    "\n",
    "The character have certain objects in your surrounding: {object_list}\n",
    "\n",
    "User query: {user_query}\n",
    "\n",
    "Judge the character response, and give 0 to 4 rating to the five personality traits, openness, meticulousness, extroversion, agreeableness and sensitivity. Output should be in a JSON format.\n",
    "E.g. output \n",
    "{{\"openness\":0, \"meticulousness\":2, \"extroversion\": 3, \"agreeableness\": 4, \"sensitivity\": 4}}\n",
    "\n",
    "Only return the JSON with no explanation.\n",
    "\"\"\"\n",
    "\n",
    "def get_big5_personality_prompt(personality: dict):\n",
    "    \"\"\"\n",
    "        Implement this method.\n",
    "        \n",
    "        Args:\n",
    "            - Dictionary containing level for each of the big5 personality.\n",
    "                Example:\n",
    "                {\n",
    "                    \"openness\": 2,\n",
    "                    \"meticulousness\": 4,\n",
    "                    \"extraversion\": 2,\n",
    "                    \"agreeableness\": 0,\n",
    "                    \"sensitivity\": 2\n",
    "                }\n",
    "        Output:\n",
    "            - string: Prompt for big5 personality.\n",
    "    \"\"\"\n",
    "    openness = personality[\"openness\"]\n",
    "    meticulousness = personality[\"meticulousness\"]\n",
    "    extraversion = personality[\"extroversion\"]\n",
    "    agreeableness = personality[\"agreeableness\"]\n",
    "    sensitivity = personality[\"sensitivity\"]\n",
    "\n",
    "    openness_desc = {0: \"dislikes changes\", 1: \"avoids changes\", 2: \"is moderate with changes\", 3: \"is open to changes\", 4: \"likes exploring\"}\n",
    "    meticulousness_desc = {0: \"let things happen\", 1: \"has relaxed approach\", 2: \"has balanced attention to details\", 3: \"is attentive to details\", 4: \"gives more attention to details\"}\n",
    "    extroversion_desc = {0: \"is an introvert\", 1: \"is less outgoing\", 2: \"has balanced social behavior\", 3: \"is more outgoing\", 4: \"is an extrovert\"}\n",
    "    agreeableness_desc = {0: \"is competitive\", 1: \"can be less agreeable\", 2: \"is competitive and agreeable in a balanced way\", 3: \"is more agreeable\", 4: \"is readily agreeable\"}\n",
    "    sensitivity_desc = {0: \"is rarely sensitive\", 1: \"is less sensitive\", 2: \"is of moderate sensitive nature\", 3: \"is frequently sensitive\", 4: \"is highly emotional\"}\n",
    "\n",
    "    statement = f\"Someone who {openness_desc[openness]}, {meticulousness_desc[meticulousness]}, \"\n",
    "    statement += f\"{extroversion_desc[extraversion]}, {agreeableness_desc[agreeableness]}, \"\n",
    "    statement += f\"and {sensitivity_desc[sensitivity]}.\"\n",
    "    \n",
    "\n",
    "    return statement \n",
    "\n",
    "\n",
    "def get_gpt35_response(messages: list):\n",
    "    openai.api_key = OPENAI_API_KEY \n",
    "    responses = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=[\"User:\"],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "\n",
    "    resp_text = \"\"\n",
    "    for response in responses:\n",
    "        choice_content = response.choices[0].delta.get('content') if response.choices else None\n",
    "        if not choice_content:\n",
    "                continue\n",
    "        resp_text += choice_content\n",
    "\n",
    "    return resp_text\n",
    "\n",
    "\n",
    "def get_test_prompt(data: dict, user_query: str, chat_history: list = []):\n",
    "    messages = []\n",
    "    system_prompt = PROMPT_TEMPLATE.format(\n",
    "        character_name=data['character_name'], backstory=data['backstory'],\n",
    "        action_list=data['action_list'], object_list=data['object_list'])\n",
    "    messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    big5_personality_prompt = get_big5_personality_prompt(data['personality_traits'])\n",
    "    messages.append({\"role\": \"system\", \"content\": big5_personality_prompt})\n",
    "\n",
    "    for chat in chat_history:\n",
    "        messages.append({\"role\": \"user\", \"content\": chat[\"user\"]})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": chat[\"assistant\"]})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": user_query})\n",
    "    return messages \n",
    "\n",
    "\n",
    "def score_prompt(data: dict, user_query: str, gpt_response: str):\n",
    "    system_prompt = SCORING_PROMPT.format(\n",
    "        character_name=data['character_name'], backstory=data['backstory'],\n",
    "        action_list=data['action_list'], object_list=data['object_list'],\n",
    "        user_query=user_query)\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_response})\n",
    "\n",
    "    openai.api_key = OPENAI_API_KEY \n",
    "    responses = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=[\"User:\"],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    resp_text = \"\"\n",
    "    for response in responses:\n",
    "        choice_content = response.choices[0].delta.get('content') if response.choices else None\n",
    "        if not choice_content:\n",
    "                continue\n",
    "        resp_text += choice_content\n",
    "\n",
    "    # Parse json\n",
    "    pattern = r'\\{(?:[^{}]|(?:\\{(?:[^{}]|(?:\\{[^{}]*\\}))*\\}))*\\}'\n",
    "    \n",
    "    # Find the first match\n",
    "    match = re.search(pattern, resp_text, re.DOTALL)\n",
    "    print(match)\n",
    "    # Load the JSON object and extract the ratings for each criterion\n",
    "    json_str = match.group()\n",
    "    return json_str.replace(\"'\", '\"')\n",
    "\n",
    "\n",
    "def run_evaluation():\n",
    "    score_filename = \"scores.csv\"\n",
    "\n",
    "    # Writing to the csv file\n",
    "    with open(score_filename, 'w', newline='') as score_file:\n",
    "        fwriter = csv.writer(score_file)\n",
    "\n",
    "        for entry in dataset.test_data_set:\n",
    "            chat_history = []\n",
    "            total_score = {\n",
    "                 \"openness\": 0,\n",
    "                 \"meticulousness\": 0,\n",
    "                 \"extroversion\": 0,\n",
    "                 \"agreeableness\": 0,\n",
    "                 \"sensitivity\": 0\n",
    "            }\n",
    "            num_chats = 0\n",
    "            for uquery in entry[\"user_query\"]:\n",
    "                prompt_to_evaluate = get_test_prompt(entry, uquery, chat_history)\n",
    "                gpt_response = get_gpt35_response(prompt_to_evaluate)\n",
    "                chat_history.append({\"user\": uquery, \"assistant\": gpt_response})\n",
    "\n",
    "                new_score = eval(score_prompt(entry, uquery, gpt_response))\n",
    "                for k,v in new_score.items():\n",
    "                     total_score[k] += (abs(v - entry[\"personality_traits\"][k]) / 4)\n",
    "                num_chats += 1\n",
    "                time.sleep(60)\n",
    "\n",
    "            avg_score = {}\n",
    "            for k,v in total_score.items():\n",
    "                avg_score[k] = round(v / num_chats, 2)\n",
    "            fwriter.writerow([entry[\"id\"], avg_score[\"openness\"],avg_score[\"meticulousness\"],avg_score[\"extroversion\"],avg_score[\"agreeableness\"],avg_score[\"sensitivity\"]])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce11cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
